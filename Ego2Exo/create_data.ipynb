{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1360d0c0",
   "metadata": {},
   "source": [
    "## Preparation of Ego2Exo Dataset for Video Domain Adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d948ad5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from collections import defaultdict, Counter\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b49afd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/newdata/tarun/datasets/ego4d_new/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7472da3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "def get_hash(input_string, size=8):\n",
    "    # Generate the hash and truncate it to 8 characters\n",
    "    hash_hex = hashlib.md5(input_string.encode()).hexdigest()[:size]\n",
    "    # Convert the hexadecimal string to an integer\n",
    "    return int(hash_hex, 16)\n",
    "\n",
    "def valid_exo(names):\n",
    "    return [n for n in names if n.startswith((\"cam\",\"gp01\",\"gp02\",\"gp03\",\"gp04\",\"gp06\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69233454",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"take_ids.txt\") as fh:\n",
    "    takes = list(map(lambda v:v.strip(), fh.readlines()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b158f0",
   "metadata": {},
   "source": [
    "## Extract text for all segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51235a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "## arrange the keysteps into <take_uid:list(segments)>\n",
    "\n",
    "keystep_path = os.path.join(root_dir, \"annotations/keystep_train.json\")\n",
    "keysteps_json = json.load(open(keystep_path))['annotations']\n",
    "\n",
    "keystep_segments = {}\n",
    "for k in takes:\n",
    "    assert k not in keystep_segments\n",
    "    keystep_segments[k] = keysteps_json[k]['segments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47ec1802",
   "metadata": {},
   "outputs": [],
   "source": [
    "## arrange the atomic descriptions into <take_uid:dict(annotator_id:list(desc))>\n",
    "\n",
    "atomic_path = os.path.join(root_dir, \"annotations/atomic_descriptions_train.json\") \n",
    "atomic_json = json.load(open(atomic_path))['annotations']\n",
    "\n",
    "atomic_annotations = {}\n",
    "for k in takes:\n",
    "    annotator_dict = {}\n",
    "    for annotations in atomic_json[k]:\n",
    "        aid = annotations['annotator_id']\n",
    "        desc = annotations['descriptions']\n",
    "        annotator_dict[aid] = desc\n",
    "    atomic_annotations[k] = annotator_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ae32c0",
   "metadata": {},
   "source": [
    "### Match the keysteps to atomic annotations takewise. for each annotator from each take, do the following:\n",
    "1. give the segment a unique id: this is a hash of the take and the segment_id within the take.\n",
    "2. identify the start and end times of the segment.\n",
    "3. from the atomic annotations, find all the instances which falls between this start and end time.\n",
    "4. concatenate these statements end to end - this forms the textual description of the keystep per annotator.\n",
    "5. if there is no atomic action description between the start and end times of a keystep from any of the annotator, then the textual description of that keystep would be the concatenation of the action descriptions from closest before and after action descriptions from any of the randomly sampled annotator. \n",
    "6. note that a single atomic descrption can be matched to multiple keysteps - since the keysteps segments can be overlapping. But this happens rarely, like 75/4262 times or lesser.\n",
    "7. To fuse texts from different annotators, we just concatenate them end to end - but there should be better ways of doing this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6cfa262c",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_to_text = defaultdict(list) ## dict with list values\n",
    "segment_to_meta = dict()\n",
    "segment_to_annotation = dict()\n",
    "take_uid = takes[0] \n",
    "\n",
    "for take_uid in takes:\n",
    "    segment_list = keystep_segments[take_uid] ## list\n",
    "    annotator_dict = atomic_annotations[take_uid] ## dict: ann_id:list of descriptions.\n",
    "\n",
    "    for idx, segment in enumerate(segment_list):\n",
    "        segment_hash = str(get_hash(str(take_uid) + str(idx)))\n",
    "        segment_to_annotation[segment_hash] = segment\n",
    "        start_time = segment['start_time']\n",
    "        end_time = segment['end_time']\n",
    "        \n",
    "        text_dict = dict()\n",
    "        best_exo = []\n",
    "        for aid in annotator_dict:\n",
    "            ann_desc = annotator_dict[aid]\n",
    "            ann_text = []\n",
    "            \n",
    "            for desc in ann_desc:\n",
    "                if start_time <= desc['timestamp'] <= end_time:\n",
    "                    ## this atomic description falls inside the segment - so should correspond to the action.\n",
    "                    ann_text.append(desc['text'][2:]) ## Ignore the subject ID.\n",
    "                    best_exo.append(desc['best_exo'])\n",
    "            if len(ann_text):\n",
    "                ann_text = \" \".join(ann_text)\n",
    "                text_dict[aid] = ann_text\n",
    "        \n",
    "        len_text = sum([len(v) for v in text_dict.values()])\n",
    "        if len_text == 0:\n",
    "            aid = random.sample(list(annotator_dict.keys()),1)[0]\n",
    "            ann_desc = annotator_dict[aid]\n",
    "            ann_text = []\n",
    "            for jdx in range(len(ann_desc)):\n",
    "                if jdx==(len(ann_desc)-1) or (ann_desc[jdx]['timestamp'] < start_time and ann_desc[jdx+1]['timestamp'] > start_time):\n",
    "                    ann_text.append(ann_desc[jdx]['text'][2:])\n",
    "                    best_exo.append(ann_desc[jdx]['best_exo'])\n",
    "                    break\n",
    "            if len(ann_desc) and (ann_desc[0]['timestamp'] > end_time):\n",
    "                    ann_text.append(ann_desc[0]['text'][2:])\n",
    "                    best_exo.append(ann_desc[0]['best_exo'])\n",
    "            else:\n",
    "                for jdx in range(1,len(ann_desc)):\n",
    "                    if (ann_desc[jdx]['timestamp'] > end_time and ann_desc[jdx-1]['timestamp'] < end_time):\n",
    "                        ann_text.append(ann_desc[jdx]['text'][2:])\n",
    "                        best_exo.append(ann_desc[jdx]['best_exo'])\n",
    "                        break\n",
    "            \n",
    "            if len(ann_text):\n",
    "                text_dict[aid] = \" \".join(ann_text)\n",
    "                            \n",
    "        if len(best_exo) == 0:\n",
    "            ## If no exo-view recorded for an ego-view segment, skip the segment. \n",
    "            continue\n",
    "        segment_to_text[segment_hash] = text_dict \n",
    "        segment.update({\n",
    "            'take_uid'  : take_uid,\n",
    "            'segment_id': idx,\n",
    "            'best_exo' : random.sample(best_exo,1)[0],# if len(best_exo) >= 1 else {}\n",
    "#             'domain'   : take_uid_to_name[take_uid]\n",
    "        })\n",
    "        \n",
    "        segment_to_meta[segment_hash] = segment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b2149f",
   "metadata": {},
   "source": [
    "## Extract labels at L1 hierarchy for all the segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "916968a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "keysteps = json.load(open(keystep_path))\n",
    "annotations = keysteps['annotations']\n",
    "taxonomy = keysteps['taxonomy']\n",
    "\n",
    "cooking = ['Making Coffee latte',\n",
    " 'Making Cucumber & Tomato Salad',\n",
    " 'Cooking Scrambled Eggs',\n",
    " 'Cooking an Omelet',\n",
    " 'Making Milk Tea',\n",
    " 'Making Sesame-Ginger Asian Salad',\n",
    " 'Cooking Tomato & Eggs',\n",
    " 'Making Chai Tea',\n",
    " 'Cooking Noodles',\n",
    " 'Cooking Sushi Rolls',\n",
    " 'Cooking Pasta']\n",
    "\n",
    "scenario_wise_mapping = {}\n",
    "for scenario in cooking:\n",
    "    \n",
    "    ## compute the parent tree.\n",
    "    idx_to_parent = {}\n",
    "    child_ids = []\n",
    "    idx_to_name = {}\n",
    "    for c,m in taxonomy[scenario].items():\n",
    "        idx_to_name[m['id']] = m['name']\n",
    "        idx_to_parent[m['id']] = m['parent_id']\n",
    "        if m['is_leafnode']:\n",
    "            child_ids.append(m['id'])\n",
    "    \n",
    "    ## map the child labels to the parents.\n",
    "    mapping = {}\n",
    "    for cid in child_ids:\n",
    "        curr = cid\n",
    "        while idx_to_parent[curr] != 0:\n",
    "            curr = idx_to_parent[curr]\n",
    "        mapping[cid] = idx_to_name[curr]\n",
    "        \n",
    "    scenario_wise_mapping[scenario] = mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f4ff9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_to_ann = {}\n",
    "all_labels = []\n",
    "for take_uid in takes:\n",
    "    ann = annotations[take_uid]\n",
    "    for idx, seg in enumerate(ann[\"segments\"]):\n",
    "        if seg['step_id'] >= 10000:\n",
    "            ## For some reason, some have this wierd seg_id, skip these.\n",
    "            continue\n",
    "        segment_hash = str(get_hash(str(take_uid) + str(idx)))\n",
    "        label_remapped_name = scenario_wise_mapping[ann[\"scenario\"]][seg['step_id']]\n",
    "        all_labels.append(label_remapped_name)\n",
    "        seg.update({\n",
    "            'l1_label_name' : label_remapped_name,\n",
    "            'take_uid'      : take_uid,\n",
    "            'segment_id'    : idx,\n",
    "            'scenario'      : ann['scenario']\n",
    "        })\n",
    "        segment_to_ann[segment_hash] = seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1b7f673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Selected based on label frequency and distribution between train and validation sets.\n",
    "valid_labels = ['Clean up',\n",
    " 'Prepare milk (boiled)',\n",
    " 'Prepare ingredients',\n",
    " 'Construct undressed salad',\n",
    " 'Make dough',\n",
    " 'Brew coffee (instant coffee)',\n",
    " 'Prepare a skillet',\n",
    " 'Make chai tea',\n",
    " 'Make pasta',\n",
    " 'Cook noodles in a skillet',\n",
    " 'Get kitchenware & utensils',\n",
    " 'Turn off the stove',\n",
    " 'Check paper recipe',\n",
    " 'Boil noodles in boiling water',\n",
    " 'Brew coffee (manual pour-over)',\n",
    " 'Make milk tea',\n",
    " 'Mix noodles with sauce in a bowl',\n",
    " 'Make salad',\n",
    " 'Serve',\n",
    " 'Cook',\n",
    " 'Add spring onions',\n",
    " 'Get Ingredients',\n",
    " 'Add water',\n",
    " 'Prepare dressing']\n",
    "\n",
    "len(set(valid_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b479b426",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_label = {idx:l for idx,l in enumerate(valid_labels)}\n",
    "label_to_idx = {v:k for k,v in idx_to_label.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5d2ace",
   "metadata": {},
   "source": [
    "## Create the json files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85d5a9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e990ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [{\"category_name\":cname,  \"category_id\":idx} for idx, cname in idx_to_label.items()]\n",
    "json_data['categories'] = categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f4a4dd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_seg = defaultdict(list)\n",
    "for seg_id, ann in segment_to_ann.items():\n",
    "    if seg_id not in segment_to_meta:\n",
    "        continue\n",
    "    if ann['l1_label_name'] in valid_labels:\n",
    "        label_to_seg[ann['l1_label_name']].append(seg_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f62aa31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_ids = []\n",
    "target_ids = []\n",
    "for segments in label_to_seg.values():\n",
    "    source = random.sample(list(segments), int(len(segments)*0.55))\n",
    "    target = [s for s in segments if s not in source]\n",
    "    \n",
    "    source_ids.extend(source)\n",
    "    target_ids.extend(target)\n",
    "seg_ids = {\n",
    "    \"source\" : source_ids,\n",
    "    \"target\" : target_ids\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d1a651a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fid_to_filename = {k:\"file.jpg\" for k in segment_to_ann}\n",
    "fid_to_category = {k:v['l1_label_name'] for k,v in segment_to_ann.items()}\n",
    "fid_to_label = {k:label_to_idx.get(v['l1_label_name'],-1) for k,v in segment_to_ann.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e5c65ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for domain in ['source', 'target']:\n",
    "    \n",
    "        ## images\n",
    "        all_ids = seg_ids[domain]\n",
    "\n",
    "        clips = []\n",
    "\n",
    "        for fid in all_ids:\n",
    "            clips.append({\n",
    "                \"filename\" : fid_to_filename[fid],\n",
    "                \"id\"       : int(fid),\n",
    "            })\n",
    "\n",
    "        ## annotations\n",
    "\n",
    "        anns = []\n",
    "\n",
    "        for fid in all_ids:\n",
    "\n",
    "            anns.append({\n",
    "                \"segment_id\" : int(fid),\n",
    "                \"category\" : fid_to_label[fid],\n",
    "                'class_name' : fid_to_category[fid]\n",
    "            })\n",
    "\n",
    "        ## metadata\n",
    "\n",
    "        meta = []\n",
    "\n",
    "        for fid in all_ids:\n",
    "            meta_dict = segment_to_meta[fid]\n",
    "            fid = int(fid)\n",
    "            \n",
    "\n",
    "            meta.append({\n",
    "                'segment_id'    : fid,\n",
    "                'start_time'  : meta_dict['start_time'],\n",
    "                'end_time'    : meta_dict['end_time'],\n",
    "                'take_uid'    : meta_dict['take_uid'],\n",
    "                'segment_index' : meta_dict['segment_id'],\n",
    "                'best_exo'    : meta_dict['best_exo']\n",
    "            })\n",
    "            \n",
    "        ## text description\n",
    "        \n",
    "        text_desc = []\n",
    "        \n",
    "        for fid in all_ids:\n",
    "            segment_id = int(fid)\n",
    "            final_text = \"\"\n",
    "            for text in segment_to_text[fid].values():\n",
    "                final_text += text\n",
    "            text_dict = {\n",
    "                'segment_id' : segment_id,\n",
    "                'text_caption' : final_text,\n",
    "                'annotator_texts' : {}\n",
    "            }\n",
    "            for ann_id, text in segment_to_text[fid].items():\n",
    "                text_dict['annotator_texts'][ann_id] = text\n",
    "            \n",
    "            text_desc.append(text_dict)\n",
    "\n",
    "        json_data[\"{}\".format(domain)] = {\n",
    "            \"clips\" : clips,\n",
    "            \"annotations\" : anns,\n",
    "            \"metadata\"    : meta,\n",
    "            \"descriptions\" : text_desc\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7a0c3c",
   "metadata": {},
   "source": [
    "## Add Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b6c1c99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "take_path = os.path.join(root_dir, \"takes.json\")\n",
    "takes = json.load(open(take_path))\n",
    "uid_to_take = {t[\"take_uid\"]:t for t in takes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c9f8869c",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_keystep_path = os.path.join(root_dir, \"annotations/keystep_val.json\")\n",
    "val_annotations = json.load(open(val_keystep_path))['annotations']\n",
    "val_annotations = {k:v for k,v in val_annotations.items() if v['scenario'] in cooking}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "21c3dc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_wise_mapping_pruned = {}\n",
    "for k,v in scenario_wise_mapping.items():\n",
    "    scenario_wise_mapping_pruned[k] = {key:val for key,val in v.items() if val in valid_labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "662ce487",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_to_ann = {}\n",
    "for take_uid, ann in val_annotations.items():\n",
    "    scenario = ann['scenario']\n",
    "\n",
    "    exos = valid_exo(uid_to_take[take_uid]['frame_aligned_videos'].keys())\n",
    "    random_exos = random.sample(exos,1)[0]\n",
    "    for idx, segment in enumerate(ann[\"segments\"]):\n",
    "        label_name = scenario_wise_mapping_pruned[scenario].get(segment['step_id'],None)\n",
    "        if label_name is not None:\n",
    "            seg_hash = str(get_hash(str(take_uid) + str(idx)))\n",
    "            segment.update({\n",
    "                'l1_label_name' : label_name,\n",
    "                'l1_label_id'   : label_to_idx[label_name],\n",
    "                'take_uid'      : take_uid,\n",
    "                'segment_index'    : idx,\n",
    "                'scenario'      : ann['scenario'],\n",
    "                'best_exo'      : {'cam_id':random_exos, 'raw_cam_id':str(int(random_exos[-2:]))}\n",
    "            })\n",
    "            seg_to_ann[seg_hash] = segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "25d13d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fid_to_filename = {k:\"file.jpg\" for k in seg_to_ann}\n",
    "fid_to_category = {k:v['l1_label_name'] for k,v in seg_to_ann.items()}\n",
    "fid_to_label = {k:v['l1_label_id'] for k,v in seg_to_ann.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6e57f02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## images\n",
    "all_ids = list(seg_to_ann.keys())\n",
    "\n",
    "clips = []\n",
    "\n",
    "for fid in all_ids:\n",
    "    clips.append({\n",
    "        \"filename\" : fid_to_filename[fid],\n",
    "        \"id\"       : int(fid),\n",
    "    })\n",
    "\n",
    "## annotations\n",
    "\n",
    "anns = []\n",
    "\n",
    "for fid in all_ids:\n",
    "\n",
    "    anns.append({\n",
    "        \"segment_id\" : int(fid),\n",
    "        \"category\" : fid_to_label[fid],\n",
    "        'class_name' : fid_to_category[fid]\n",
    "    })\n",
    "\n",
    "## metadata\n",
    "\n",
    "meta = []\n",
    "\n",
    "for fid in all_ids:\n",
    "    meta_dict = seg_to_ann[fid]\n",
    "    fid = int(fid)\n",
    "\n",
    "\n",
    "    meta.append({\n",
    "        'segment_id'    : fid,\n",
    "        'start_time'  : meta_dict['start_time'],\n",
    "        'end_time'    : meta_dict['end_time'],\n",
    "        'take_uid'    : meta_dict['take_uid'],\n",
    "        'segment_index' : meta_dict['segment_index'],\n",
    "        'best_exo'    : meta_dict['best_exo']\n",
    "    })\n",
    "    \n",
    "text_desc = []\n",
    "        \n",
    "for fid in all_ids:\n",
    "    segment_id = int(fid)\n",
    "    final_text = \"\"\n",
    "    text_dict = {\n",
    "        'segment_id' : segment_id,\n",
    "        'text_caption' : final_text,\n",
    "        'annotator_texts' : {}\n",
    "    }\n",
    "\n",
    "    text_desc.append(text_dict)\n",
    "    \n",
    "    \n",
    "json_data['source_val'] = {\n",
    "            \"clips\" : clips,\n",
    "            \"annotations\" : anns,\n",
    "            \"metadata\"    : meta,\n",
    "            \"descriptions\" : text_desc\n",
    "        }\n",
    "\n",
    "\n",
    "json_data['target_val'] = {\n",
    "            \"clips\" : clips,\n",
    "            \"annotations\" : anns,\n",
    "            \"metadata\"    : meta,\n",
    "            \"descriptions\" : text_desc\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0fd1befe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ego2exo = {\n",
    "    'categories' : json_data['categories'],\n",
    "    'exo_train'  : json_data['source'],\n",
    "    'exo_val'    : json_data['source_val'],\n",
    "    'ego_train'  : json_data['target'],\n",
    "    'ego_val'    : json_data['target_val'],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0d3d21",
   "metadata": {},
   "source": [
    "## Add training frames and segment_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c6353516",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_mapping(n_frames, window_size=32, stride=16, fps=30, frames=True):\n",
    "    \"\"\"\n",
    "    Given a video of length T, window W and stride S, generate mapping between index and the feature window used\n",
    "    to compute the features.\n",
    "    mapping: dict(key:idx, val:(start_frame, end_frame))\n",
    "    So, the feature at position idx is computed using the frames from (start_frame, end_frame).\n",
    "    \"\"\"\n",
    "    ## 0-31 -> 1, 16-47 -> 2, ....\n",
    "    ## also add a loop-back for edge cases\n",
    "    idx = 0\n",
    "    starting_frame, ending_frame = 0, window_size-1\n",
    "    mapping = dict()\n",
    "    while ending_frame < n_frames:\n",
    "        mapping[idx] = (starting_frame, ending_frame)\n",
    "        starting_frame += stride\n",
    "        ending_frame = starting_frame + window_size-1\n",
    "        idx += 1\n",
    "    if n_frames % stride != 0:\n",
    "        ending_frame = n_frames-1\n",
    "        starting_frame = ending_frame - (window_size-1)\n",
    "        mapping[idx] = (starting_frame, ending_frame)\n",
    "    if not frames:\n",
    "        mapping = {k:(v[0]/fps,v[1]/fps) for k,v in mapping.items()}\n",
    "    return mapping\n",
    "\n",
    "def get_matching_indices(start, end, frame_idx, sec=True, fps=30):\n",
    "    \"\"\"\n",
    "    Given a start and end time of a video clip, find what feature_ids correspond to that particular clip.\n",
    "    There can be more than one feature_idx, so we return the list of all such indices.\n",
    "    \"\"\"\n",
    "    if sec:\n",
    "        start = start*fps\n",
    "        end = end*fps\n",
    "    \n",
    "    matching_list = []\n",
    "        \n",
    "    idx = 0\n",
    "    while frame_idx[idx][1] < start:\n",
    "        idx += 1\n",
    "\n",
    "    while (idx < len(frame_idx)) and (frame_idx[idx][0] < end) :\n",
    "        matching_list.append(idx)\n",
    "        idx += 1\n",
    "    \n",
    "    return matching_list\n",
    "\n",
    "def get_frame_indices(start, end, window_size=32, stride=16, sec=True, fps=30):\n",
    "    \"\"\"\n",
    "    Given start and end times of a video clip and a window size and stride, this outputs a list of frame \n",
    "    boundaries which have to be forward passed for computing feature for that clip.\n",
    "    \"\"\"\n",
    "    if sec:\n",
    "        start = int(start*fps)\n",
    "        end = int(end*fps)\n",
    "        \n",
    "    frame_indices = []\n",
    "    \n",
    "    curr_start = start\n",
    "    curr_end = start+(window_size-1)\n",
    "    \n",
    "#     frame_indices.append(curr_start)\n",
    "    \n",
    "    while curr_end <= end:\n",
    "        frame_indices.append((curr_start,curr_end))\n",
    "        curr_start += stride\n",
    "        if curr_end == end:\n",
    "            break\n",
    "        curr_end = curr_start + (window_size-1)\n",
    "        \n",
    "    if curr_end > end:\n",
    "        curr_end = end\n",
    "        curr_start = max(0, curr_end - (window_size-1))\n",
    "        frame_indices.append((curr_start, curr_end))\n",
    "    \n",
    "    return frame_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d2e4b362",
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_to_frame = {t[\"take_uid\"]:get_index_mapping(int(t['duration_sec'] * 30)) for t in takes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "87849720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ego_train,4100\n",
      "ego_val,3168\n",
      "exo_train,4986\n",
      "exo_val,3168\n"
     ]
    }
   ],
   "source": [
    "feature_root = \"features/omnivore_video/\"\n",
    "for split in ['ego_train', 'ego_val', 'exo_train', 'exo_val']:\n",
    "    \n",
    "    segid_to_meta = {m['segment_id']:m for m in ego2exo[split][\"metadata\"]}\n",
    "    \n",
    "    features = []\n",
    "    for segid,meta in segid_to_meta.items():\n",
    "\n",
    "        take_uid = meta[\"take_uid\"]\n",
    "        if take_uid not in uid_to_take:\n",
    "#             print(take_uid)\n",
    "            continue\n",
    "\n",
    "        if \"ego\" in split:\n",
    "            all_cameras = uid_to_take[take_uid][\"frame_aligned_videos\"].keys()\n",
    "            ego_camera = [a for a in all_cameras if \"aria\" in a or \"gp05\" in a]\n",
    "            ego_camera = random.choice(ego_camera)\n",
    "            if \"aria\" in ego_camera:\n",
    "                cam = \"{}_{}\".format(ego_camera, \"rgb\")\n",
    "                stream_info = uid_to_take[take_uid][\"frame_aligned_videos\"][ego_camera]['rgb']\n",
    "                filepath = \"{}/frame_aligned_videos/downscaled/448/{}_{}.mp4\".format(uid_to_take[take_uid][\"root_dir\"], stream_info['cam_id'], stream_info['stream_id'])\n",
    "            elif \"gp05\" in ego_camera:\n",
    "                cam = \"{}_0\".format(ego_camera)\n",
    "                stream_info = uid_to_take[take_uid][\"frame_aligned_videos\"][ego_camera]['0']\n",
    "                filepath = \"{}/frame_aligned_videos/downscaled/448/{}.mp4\".format(uid_to_take[take_uid][\"root_dir\"], stream_info['cam_id'])\n",
    "            else:\n",
    "                raise ValueError\n",
    "        else:\n",
    "            if (meta['best_exo'] is None) or (meta['best_exo']['cam_id'] is None):\n",
    "                ## choose a random id\n",
    "                all_cameras = uid_to_take[take_uid][\"frame_aligned_videos\"].keys()\n",
    "                exo_cameras = [a for a in all_cameras if a.startswith((\"gp01\",\"gp02\",\"gp03\",\"gp04\",\"gp06\",\"cam\"))]\n",
    "                exo_choice = random.sample(exo_cameras,1)[0]\n",
    "                cam = \"{}_0\".format(exo_choice)\n",
    "            else:\n",
    "                ## choose the best id\n",
    "                cam = \"{}_0\".format(meta['best_exo']['cam_id']) \n",
    "                exo_choice = meta['best_exo']['cam_id']\n",
    "                if \"gp05\" == exo_choice:\n",
    "                    exo_choice = \"gp04\"\n",
    "            stream_info = uid_to_take[take_uid][\"frame_aligned_videos\"][exo_choice]['0']\n",
    "            filepath = \"{}/frame_aligned_videos/downscaled/448/{}.mp4\".format(uid_to_take[take_uid][\"root_dir\"], stream_info['cam_id'])\n",
    "\n",
    "        features.append({\n",
    "            'id' : segid,\n",
    "            'video_file_name': filepath,\n",
    "            'feature_file_name' : os.path.join(feature_root, \"{}_{}.pt\".format(take_uid,cam)),\n",
    "            'feature_indices' : get_matching_indices(meta[\"start_time\"], meta[\"end_time\"], uid_to_frame[meta[\"take_uid\"]], sec=True),\n",
    "            'frame_indices' : get_frame_indices(meta[\"start_time\"], meta[\"end_time\"], sec=True)\n",
    "        })\n",
    "    \n",
    "    print(\"{},{}\".format(split, len(features)))\n",
    "    ego2exo[split]['clips'] = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0e9309ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ego_train\n",
      "ego_val\n",
      "exo_train\n",
      "exo_val\n"
     ]
    }
   ],
   "source": [
    "## normalize segments across all the domains and data.\n",
    "for split in ['ego_train', 'ego_val', 'exo_train', 'exo_val']:\n",
    "    print(split)\n",
    "    valid_ids = [c[\"id\"] for c in ego2exo[split][\"clips\"]]\n",
    "    \n",
    "    for ks in ego2exo[split].keys():\n",
    "        if ks == \"clips\":\n",
    "            continue\n",
    "        old_list = ego2exo[split][ks]\n",
    "        new_list = [o for o in old_list if o[\"segment_id\"] in valid_ids]\n",
    "        ego2exo[split][ks] = new_list\n",
    "        assert len(new_list) == len(ego2exo[split]['clips'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "11335b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ego2exo.json\", \"w\") as fh:\n",
    "    json.dump(ego2exo, fh, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
