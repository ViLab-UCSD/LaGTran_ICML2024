{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35d49d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "from itertools import chain\n",
    "# import os\n",
    "%config Completer.use_jedi = False\n",
    "\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c0ca0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f97479be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ngrams(text, n):\n",
    "    \"\"\"\n",
    "    Function to generate all ngrams for a given 'n' from a string.\n",
    "\n",
    "    :param text: The input string from which to generate ngrams.\n",
    "    :param n: The size of the ngram.\n",
    "    :return: A list of ngrams as strings.\n",
    "    \"\"\"\n",
    "    if isinstance(n, list):\n",
    "        ngram_list = []\n",
    "        for ni in n:\n",
    "            ngram_list += generate_ngrams(text, ni)\n",
    "        return ngram_list\n",
    "    # Split the text into words\n",
    "    words = text.split()\n",
    "\n",
    "    # Generate ngrams\n",
    "    ngram_list = [' '.join(gram) for gram in ngrams(words, n)]\n",
    "\n",
    "    return ngram_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7c3c3c",
   "metadata": {},
   "source": [
    "## DomainNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a531b911",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(similarity_matrix, gt_label, topk=5):\n",
    "    pseudoLabel = similarity_matrix.topk(topk, 1).indices  \n",
    "    gt_label = torch.Tensor(gt_label).view(-1,1).repeat(1,topk)\n",
    "    matched_labels = (torch.Tensor(pseudoLabel) == torch.Tensor(gt_label))\n",
    "    top1_acc = matched_labels[:,0].sum()/len(gt_label)\n",
    "    topk_acc = matched_labels.any(1).sum()/len(gt_label)\n",
    "    return top1_acc, topk_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "391222ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(0.7702), tensor(0.9054))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c358c0a0263843bc8a742e2c4de9d86e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(0.8671), tensor(0.9592))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "089748f860c84a6f9611bc9515dd6565",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(0.8021), tensor(0.9496))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b55bd68451b047c9922eab770d4582d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(0.7238), tensor(0.8838))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38ba2965026d430a90d178f3b1464dbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "name = \"officeHome\"\n",
    "\n",
    "# for domain in [\"clipart\", \"sketch\", \"painting\"]:\n",
    "for domain in ['art', 'product', 'real', 'clipart']:\n",
    "\n",
    "    data = json.load(open(\"../metadata/{}.json\".format(name.lower())))\n",
    "    geo = data[f'{domain}_train']\n",
    "    id_to_classid = {ann[\"image_id\"]:ann[\"category\"] for ann in geo[\"annotations\"]}\n",
    "\n",
    "    # classnames = [v['category_name'].replace(\"+\",\" \").replace(\"_\",\" \") for v in data['categories']]\n",
    "    # classnames = [v['category_name'].replace(\"_indoor\",\"\").replace(\"_outdoor\",\"\").replace(\"_\",\" \") for v in data['categories']]\n",
    "    classnames = [v['category_name'].replace(\"_\",\" \") for v in data['categories']]\n",
    "    class_embeddings = model.encode(classnames)\n",
    "\n",
    "    id_to_tags = {m[\"image_id\"]: generate_ngrams(m[\"blip2_cap\"], [1,2]) for m in geo[\"metadata\"]}\n",
    "    all_flickrids = list(id_to_tags.keys())\n",
    "    all_tags = [id_to_tags[f] for f in all_flickrids]\n",
    "    tag_lens = [len(t) for t in all_tags]\n",
    "    MAX_TAG_LEN=40#max(tag_lens)\n",
    "\n",
    "    padded_tags = []\n",
    "    mask = []\n",
    "    for p in all_tags:\n",
    "        pad_len = max(0, MAX_TAG_LEN-len(p))\n",
    "        padded_tags.append(p[:MAX_TAG_LEN] + ['EOS']*pad_len)\n",
    "        mask.append([1]*min(MAX_TAG_LEN, len(p)) + [0]*pad_len)\n",
    "    mask = torch.Tensor(mask)\n",
    "\n",
    "    # mask.shape\n",
    "\n",
    "    flattened_tags = list(chain.from_iterable(padded_tags))\n",
    "\n",
    "    len(flattened_tags)\n",
    "\n",
    "    tag_embedding = model.encode(flattened_tags, batch_size=256)\n",
    "\n",
    "    # tag_embedding.shape\n",
    "\n",
    "    similarity = util.cos_sim(tag_embedding, class_embeddings)\n",
    "\n",
    "    # similarity.shape\n",
    "\n",
    "    similarity_reshaped = similarity.reshape(*mask.shape, -1)\n",
    "\n",
    "    mask = mask[...,None]\n",
    "\n",
    "    masked_similarity = similarity_reshaped * mask\n",
    "\n",
    "    pseudo_labels = masked_similarity.max(1).values\n",
    "\n",
    "    gt_label = [id_to_classid[f] for f in all_flickrids]\n",
    "\n",
    "    print(get_accuracy(pseudo_labels, gt_label))\n",
    "\n",
    "    tag_label = pseudo_labels.argmax(1).cpu().numpy()\n",
    "\n",
    "    write_str = \"\"\n",
    "    with open(\"../hard_labels/{}_{}_{}_tagMatchPL.txt\".format(name, domain, domain), \"w\") as fh:\n",
    "        for pl, fid in tqdm(zip(tag_label, all_flickrids)):\n",
    "            write_str += f\"{fid} \"\n",
    "            write_str += f\"{pl}\"\n",
    "            write_str += \"\\n\"\n",
    "        fh.write(write_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d932b0b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp officeHome_product_product_tagMatchPL.txt officeHome_art_product_tagMatchPL.txt\n",
      "cp officeHome_real_real_tagMatchPL.txt officeHome_art_real_tagMatchPL.txt\n",
      "cp officeHome_clipart_clipart_tagMatchPL.txt officeHome_art_clipart_tagMatchPL.txt\n",
      "cp officeHome_art_art_tagMatchPL.txt officeHome_product_art_tagMatchPL.txt\n",
      "cp officeHome_real_real_tagMatchPL.txt officeHome_product_real_tagMatchPL.txt\n",
      "cp officeHome_clipart_clipart_tagMatchPL.txt officeHome_product_clipart_tagMatchPL.txt\n",
      "cp officeHome_art_art_tagMatchPL.txt officeHome_real_art_tagMatchPL.txt\n",
      "cp officeHome_product_product_tagMatchPL.txt officeHome_real_product_tagMatchPL.txt\n",
      "cp officeHome_clipart_clipart_tagMatchPL.txt officeHome_real_clipart_tagMatchPL.txt\n",
      "cp officeHome_art_art_tagMatchPL.txt officeHome_clipart_art_tagMatchPL.txt\n",
      "cp officeHome_product_product_tagMatchPL.txt officeHome_clipart_product_tagMatchPL.txt\n",
      "cp officeHome_real_real_tagMatchPL.txt officeHome_clipart_real_tagMatchPL.txt\n"
     ]
    }
   ],
   "source": [
    "for src in ['art', 'product', 'real', 'clipart']:\n",
    "    for tgt in ['art', 'product', 'real', 'clipart']:\n",
    "        if src == tgt:\n",
    "            continue\n",
    "        print(f\"cp officeHome_{tgt}_{tgt}_tagMatchPL.txt officeHome_{src}_{tgt}_tagMatchPL.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d89e3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_tag_label = torch.nn.functional.softmax(pseudo_labels/0.07, dim=-1).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aab22aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_str = \"\"\n",
    "with open(\"../soft_labels/{}_{}_tagPL.txt\".format(name, domain), \"w\") as fh:\n",
    "    for pl, fid in tqdm(zip(soft_tag_label, all_flickrids)):\n",
    "        write_str += f\"{fid} \"\n",
    "        vals = list(map(str, pl.tolist()))\n",
    "        write_str += \" \".join(vals)\n",
    "        write_str += \"\\n\"\n",
    "    fh.write(write_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60135b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "name, domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d4e5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(tag_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b72799",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
