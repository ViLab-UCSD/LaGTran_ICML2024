{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe2bf34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "# import os\n",
    "%config Completer.use_jedi = False\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ff2c38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2031dcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCaptionLabels(json_dict):\n",
    "    \n",
    "    annotations = {ann[\"image_id\"]:ann[\"category\"] for ann in json_dict[\"annotations\"]}\n",
    "    captions    = {im[\"image_id\"]:im[\"caption\"] for im in json_dict[\"metadata\"]}\n",
    "    capLabels   = [(imid, captions[imid], annotations[imid]) for imid in annotations.keys()]\n",
    "    \n",
    "    return zip(*capLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ba58e9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load sentences from GeoPlaces\n",
    "# geop = json.load(open(\"/home/tarun/metadata/geoPlaces_metadata.json\"))\n",
    "geop = json.load(open(\"/home/tarun/metadata/geoImnet_metadata.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8f82a4e9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "usa_train = geop[\"usa_train\"]\n",
    "usa_fids, usa_captions, usa_labels = getCaptionLabels(usa_train)\n",
    "\n",
    "asia_train = geop[\"asia_train\"]\n",
    "asia_fids, asia_captions, asia_labels = getCaptionLabels(asia_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fe72093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_name = {int(cat[\"category_id\"]):cat[\"category_name\"] for cat in geop[\"categories\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "14467189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14716148186:palace:Fantasmic! at Disney's Hollywood Studios\n",
      "8568509223:jean:Outgrowing my Pants\n",
      "855424645:dik-dik:Günther's Dik-dik\n",
      "3601624346:promontory:2009-05_sf_visit-02\n",
      "899731661:ammunition:Spent Shotgun Shells\n",
      "7717612526:control_center:Launch Control Center\n",
      "2787788207:leafhopper:A colorful red-banded leafhopper\n",
      "6358711985:tramway:Queen Street, east from James Street\n",
      "6087478847:control_center:TWiT Control Center\n",
      "8670554260:marigold:Marigolds\n"
     ]
    }
   ],
   "source": [
    "annotations = {ann[\"image_id\"]:ann[\"category\"] for ann in usa_train[\"annotations\"]}\n",
    "captions    = {im[\"image_id\"]:im[\"caption\"] for im in usa_train[\"metadata\"]}\n",
    "\n",
    "flickrIds = list(annotations.keys())\n",
    "\n",
    "for j in range(10):\n",
    "    fid = random.choice(flickrIds)\n",
    "    print(\"{}:{}:{}\".format(fid, id_to_name[annotations[fid]], captions[fid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "68cc7486",
   "metadata": {},
   "outputs": [],
   "source": [
    "usa_caption_embeddings = model.encode(usa_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "512c7a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "asia_caption_embeddings = model.encode(asia_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9d8d4fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity_acc(source_embed, target_embed, source_label, target_label, within=False, topks=[1,5]):\n",
    "    \n",
    "    topk = max(topks)\n",
    "        \n",
    "    if within:\n",
    "        similarity_matrix = util.cos_sim(source_embed, source_embed)\n",
    "        mostSimilar = similarity_matrix.topk(topk+1, 1).indices\n",
    "        mostSimilar = mostSimilar[:,1:]\n",
    "    else:\n",
    "        similarity_matrix = util.cos_sim(source_embed, target_embed)\n",
    "        mostSimilar = similarity_matrix.topk(topk, 1).indices\n",
    "    \n",
    "    similarLabels = torch.Tensor(target_label)[mostSimilar.long().reshape(-1)].reshape(-1, topk)\n",
    "    source_label = torch.Tensor(source_label).view(-1,1).repeat(1,topk)\n",
    "    \n",
    "    matched_labels = (torch.Tensor(similarLabels) == torch.Tensor(source_label))\n",
    "                      \n",
    "    top1_acc = matched_labels[:,0].sum()/len(source_label)\n",
    "    topk_acc = matched_labels.any(1).sum()/len(source_label)\n",
    "        \n",
    "    return top1_acc, topk_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "994a1fe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.4303), tensor(0.5031))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similarity_acc(usa_caption_embeddings, asia_caption_embeddings, usa_labels, asia_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1514fb5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.4758), tensor(0.5380))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similarity_acc(asia_caption_embeddings, usa_caption_embeddings, asia_labels, usa_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d6ec8a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.7101), tensor(0.7818))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similarity_acc(usa_caption_embeddings, usa_caption_embeddings, usa_labels, usa_labels, within=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "af159547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.7500), tensor(0.8121))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similarity_acc(asia_caption_embeddings, asia_caption_embeddings, asia_labels, asia_labels, within=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9a4bd8be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154908, 384)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usa_caption_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1672a67a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "similarity_matrix = util.cos_sim(usa_caption_embeddings, asia_caption_embeddings)\n",
    "\n",
    "mostSimilar = similarity_matrix.topk(2, 1).indices\n",
    "mostSimilar = mostSimilar[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "302d6fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4333)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mostSimilar_labels = torch.Tensor(asia_labels)[mostSimilar.long()]\n",
    "equal = torch.Tensor(mostSimilar_labels) == torch.Tensor(usa_labels)\n",
    "torch.sum(equal)/len(usa_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "66621356",
   "metadata": {},
   "outputs": [],
   "source": [
    "equal_ids = torch.where((~equal).float())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0803c619",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11819430984:traffic_light:Bicycle signs and pavement markings don't match, Pennsylvania Avenue, Washington, DC USA <=> 17341121131:street_sign:Street signs\n",
      "\n",
      "9425801330:bikini:All Women Lifeguard Tournament 2013 <=> 177367307:billboard:Nike woman\n",
      "\n",
      "13340337515:beacon:New Jersey's \"Big Ass\" Lightbulb... <=> 26803144466:bulbul:The lovely bulbul....\n",
      "\n",
      "10849409385:warplane:Color of NAS Whidbey Island's A-6E Intruder & EA-6B Prowler Gate Guards & Night <=> 8440422131:picket_fence:SDIM1263_5  Dom 5, Village Skrepyaschevo (Скрепящево).   Purple garden gate in picket fence.\n",
      "\n",
      "2640339648:tender:Tender boat \"E-Z Rider\" at Scituate Harbor <=> 6194147253:bucket:Sailboat\n",
      "\n",
      "14108517504:gold_plate:Monmouth University, West Long Branch, New Jersey <=> 8894954789:fortress:The NW Tower\n",
      "\n",
      "15824366586:cemetery:96.LeonardMatlovich.CongressionalCemetery.WDC.11November2014 <=> 10477340126:fountain:0808 Kerman - Rayen - 239\n",
      "\n",
      "4969483171:sand:Exodus stretches (and soccer!) <=> 8700098374:african_elephant:Elephant exodus.\n",
      "\n",
      "112290218:pooch:crosbypi <=> 5663153697:air_conditioner:stanley\n",
      "\n",
      "12075164366:shoe_shop:Everett & Violet At B&D Burgers <=> 4488796394:sarong:Ella Restaurant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for j in np.random.choice(equal_ids, 10):\n",
    "    asia_id = mostSimilar[j]\n",
    "    print(\"{}:{}:{} <=> {}:{}:{}\\n\".format(usa_fids[j],\n",
    "        id_to_name[usa_labels[j]], \\\n",
    "                                     usa_captions[j], \\\n",
    "                                           asia_fids[asia_id],\n",
    "                                     id_to_name[asia_labels[asia_id]], \\\n",
    "                                                  asia_captions[asia_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e4d04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in np.random.choice(range(170000), 10):\n",
    "    asia_id = mostSimilar[j]\n",
    "    print(\"{}:{}:{} <=> {}:{}:{}\\n\".format(usa_fids[j],\n",
    "        id_to_name[usa_labels[j]], \\\n",
    "                                     usa_captions[j], \\\n",
    "                                           asia_fids[asia_id],\n",
    "                                     id_to_name[asia_labels[asia_id]], \\\n",
    "                                                  asia_captions[asia_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c573d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in np.random.choice(range(170000), 20):\n",
    "    asia_id = mostSimilar[j]\n",
    "    print(\"{}:{}:{} <=> {}:{}:{}\\n\".format(asia_fids[j],\n",
    "        id_to_name[asia_labels[j]], \\\n",
    "                                     asia_captions[j], \\\n",
    "                                           asia_fids[asia_id],\n",
    "                                     id_to_name[asia_labels[asia_id]], \\\n",
    "                                                  asia_captions[asia_id]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9da8e0",
   "metadata": {},
   "source": [
    "## Train city prediction model using caption input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a857006",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b357615f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCaptionLabels(json_dict, usa=True):\n",
    "    \n",
    "    filenames = {im[\"id\"]:im[\"filename\"] for im in json_dict[\"images\"]}\n",
    "        \n",
    "    captions    = {im[\"image_id\"]:random.choice([im[\"blip_cap_1\"], im[\"blip_cap_2\"]]) for im in json_dict[\"metadata\"]}\n",
    "    capLabels   = {filenames[imid]:captions[imid] for imid in filenames.keys()}\n",
    "    \n",
    "    return capLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35dbfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "geop = json.load(open(\"/newfoundland2/tarun/datasets/Places205/data/vision/torralba/deeplearning/GeoDA/geoPlaces.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4467374a",
   "metadata": {},
   "outputs": [],
   "source": [
    "usa_train = geop[\"usa_train\"]\n",
    "fn2cap = getCaptionLabels(usa_train)\n",
    "\n",
    "asia_train = geop[\"asia_train\"]\n",
    "fn2cap.update(getCaptionLabels(asia_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4586735f",
   "metadata": {},
   "outputs": [],
   "source": [
    "usa_test = geop[\"usa_test\"]\n",
    "fn2cap.update(getCaptionLabels(usa_test))\n",
    "\n",
    "asia_test = geop[\"asia_test\"]\n",
    "fn2cap.update(getCaptionLabels(asia_test))q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63842be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d258008",
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile = \"../geoData/places205/latlon_train_cities.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f4ae00",
   "metadata": {},
   "outputs": [],
   "source": [
    "latlon = pd.read_csv(datafile, header=None, sep=' ').to_dict('list')\n",
    "fn2label = dict(zip(latlon[0], latlon[1]))\n",
    "\n",
    "cap2label = []\n",
    "for fn in tqdm(list(fn2label.keys())):\n",
    "    cap2label.append((fn2cap[fn], fn2label[fn]))\n",
    "#     if fn in fn2cap:\n",
    "        \n",
    "#     else:\n",
    "#         print(fn)\n",
    "\n",
    "features = model.encode([c[0] for c in tqdm(cap2label)])\n",
    "labels = [c[1] for c in cap2label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251cd33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.25, random_state=42)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedb24d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26484a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=0, multi_class=\"multinomial\", max_iter=500, verbose=10).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce97688b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# latlon = pd.read_csv(datafile.replace(\"train\", \"test\"), header=None, sep=' ').to_dict('list')\n",
    "# fn2label = dict(zip(latlon[0], latlon[1]))\n",
    "\n",
    "# cap2label = []\n",
    "# for fn in tqdm(list(fn2label.keys())):\n",
    "#     if fn in fn2cap:\n",
    "#         cap2label.append((fn2cap[fn], fn2label[fn]))\n",
    "\n",
    "# features_test = model.encode([c[0] for c in cap2label])\n",
    "# labels_test = [c[1] for c in cap2label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f010db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.decision_function(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b33fbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1c24b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(torch.Tensor(predictions), torch.Tensor(y_test).view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a5c92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,5)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "\n",
    "    for k in topk:\n",
    "        #correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "        correct_k = correct[:k].float().sum()\n",
    "        res.append(correct_k.mul_(100.0 / batch_size).item())\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394c6dfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
