{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19596bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db946452",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flist_reader(flist):\n",
    "    flist = pd.read_csv(flist, sep=' ', header=None).to_dict('list')\n",
    "    return flist[0], flist[1]\n",
    "\n",
    "def split_into_train_test(filename):\n",
    "    \"\"\"\n",
    "    Split the file with format <fname label_id> into 80-20 train-test split.\n",
    "    \"\"\"\n",
    "\n",
    "    files, labels = flist_reader(filename)\n",
    "    \n",
    "    ## split into train, test 80-20 for each label.\n",
    "\n",
    "    train_files, train_labels = [], []\n",
    "    test_files, test_labels = [], []\n",
    "\n",
    "    for label in set(labels):\n",
    "        label_files = [f for f, l in zip(files, labels) if l == label]\n",
    "        label_labels = [l for f, l in zip(files, labels) if l == label]\n",
    "\n",
    "        num_train = int(len(label_files) * 0.8)\n",
    "        train_files.extend(label_files[:num_train])\n",
    "        train_labels.extend(label_labels[:num_train])\n",
    "        test_files.extend(label_files[num_train:])\n",
    "        test_labels.extend(label_labels[num_train:])\n",
    "\n",
    "    ## write to train and test files.\n",
    "\n",
    "    train_df = pd.DataFrame({\"fname\" : train_files, \"label\" : train_labels})\n",
    "    test_df = pd.DataFrame({\"fname\" : test_files, \"label\" : test_labels})\n",
    "\n",
    "    train_df.to_csv(filename.replace(\"all\", \"train\"), index=False, header=False, sep=\" \")\n",
    "    test_df.to_csv(filename.replace(\"all\", \"test\"), index=False, header=False, sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46f865e",
   "metadata": {},
   "outputs": [],
   "source": [
    "geoyfcc = json.load(open(\"/home/tarun/metadata/geoyfcc.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc3507b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for domain in [\"usa\", \"asia\"]:\n",
    "    train = geoyfcc[\"{}_train\".format(domain)]\n",
    "    id_to_fname = {im[\"id\"]:im[\"filename\"] for im in train[\"images\"]}\n",
    "    id_to_class = {im[\"image_id\"]:im[\"category\"] for im in train[\"annotations\"]}\n",
    "\n",
    "    with open(\"/home/tarun/LangBasedGeoDA/data/geoyfcc/{}_all.txt\".format(domain), \"w\") as fh:\n",
    "        write_str = \"\"\n",
    "        for im in train[\"images\"]:\n",
    "            fname = id_to_fname[im[\"id\"]].partition(\"/newdata/tarun/datasets/GeoYFCC/\")[-1]\n",
    "            write_str += \"{} {}\\n\".format(fname, id_to_class[im[\"id\"]])\n",
    "        fh.write(write_str)\n",
    "    split_into_train_test(\"../data/geoyfcc/{}_all.txt\".format(domain))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb17025c",
   "metadata": {},
   "source": [
    "## Split metadata into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a9c962a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "def flist_reader(flist):\n",
    "    flist = pd.read_csv(flist, sep=' ', header=None).to_dict('list')\n",
    "    return flist[0], flist[1]\n",
    "\n",
    "def get_names(name):\n",
    "    return \"/newdata/tarun/datasets/GeoYFCC/\" + name # name.split(\"/\")[-1].split(\".\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd1a0aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.load(open(\"../metadata/geoyfcc_old.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c111038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usa/images\n",
      "usa/annotations\n",
      "usa/metadata\n",
      "asia/images\n",
      "asia/annotations\n",
      "asia/metadata\n"
     ]
    }
   ],
   "source": [
    "for domain in [\"usa\", \"asia\"]:\n",
    "    fields = [\"images\", \"annotations\", \"metadata\"]\n",
    "\n",
    "    dom_data = data[\"{}_train\".format(domain)]\n",
    "    train_files = flist_reader(\"../data/geoyfcc/{}_train.txt\".format(domain))[0]\n",
    "    train_files = list(map(get_names, train_files))\n",
    "    test_files = flist_reader(\"../data/geoyfcc/{}_test.txt\".format(domain))[0]\n",
    "    test_files = list(map(get_names, test_files))\n",
    "\n",
    "    fname_to_fid = {m[\"filename\"]:m[\"id\"] for m in dom_data[\"images\"]}\n",
    "\n",
    "    train_fids = [fname_to_fid[fn] for fn in train_files]\n",
    "    test_fids = [fname_to_fid[fn] for fn in test_files]\n",
    "\n",
    "    for f in fields:\n",
    "        \n",
    "        print(\"{}/{}\".format(domain, f))\n",
    "\n",
    "        train_set = []\n",
    "        test_set = []\n",
    "        \n",
    "        if f == \"images\":\n",
    "            id_to_content = {im.get(\"id\"):im for im in dom_data[f]}\n",
    "        else:\n",
    "            id_to_content = {im.get(\"id\", im[\"image_id\"]):im for im in dom_data[f]}\n",
    "        train_set = [id_to_content[fid] for fid in train_fids]\n",
    "        test_set = [id_to_content[fid] for fid in test_fids]\n",
    "        data['{}_train'.format(domain)][f] = train_set\n",
    "        data['{}_test'.format(domain)][f] = test_set\n",
    "\n",
    "with open(\"../metadata/geoyfcc.json\", \"w\") as fh:\n",
    "    json.dump(data, fh, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
