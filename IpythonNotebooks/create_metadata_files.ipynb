{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d948ad5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict, Counter\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7472da3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "def get_hash(input_string, size=8):\n",
    "    # Generate the hash and truncate it to 8 characters\n",
    "    hash_hex = hashlib.md5(input_string.encode()).hexdigest()[:size]\n",
    "    # Convert the hexadecimal string to an integer\n",
    "    return int(hash_hex, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "69233454",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"cooking_keystep_atomic_common_takes.txt\") as fh:\n",
    "    takes = list(map(lambda v:v.strip(), fh.readlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fa9d179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(takes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37c67a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_str = \"\"\n",
    "for t in takes:\n",
    "    write_str += \"egoexo -o /newdata/tarun/datasets/ego4d --benchmarks keystep --parts takes --uids {} --yes\\n\".format(t)\n",
    "with open(\"takes_download.sh\", \"w\") as fh:\n",
    "    fh.write(write_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b158f0",
   "metadata": {},
   "source": [
    "## Extract text for all segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51235a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "## arrange the keysteps into <take_uid:list(segments)>\n",
    "\n",
    "keysteps_json = json.load(open(\"annotations/keystep_train.json\"))['annotations']\n",
    "\n",
    "keystep_segments = {}\n",
    "for k in takes:\n",
    "    assert k not in keystep_segments\n",
    "    keystep_segments[k] = keysteps_json[k]['segments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47ec1802",
   "metadata": {},
   "outputs": [],
   "source": [
    "## arrange the atomic descriptions into <take_uid:dict(annotator_id:list(desc))>\n",
    "\n",
    "atomic_json = json.load(open(\"annotations/atomic_descriptions_train.json\"))['annotations']\n",
    "\n",
    "atomic_annotations = {}\n",
    "for k in takes:\n",
    "    annotator_dict = {}\n",
    "    for annotations in atomic_json[k]:\n",
    "        aid = annotations['annotator_id']\n",
    "        desc = annotations['descriptions']\n",
    "        annotator_dict[aid] = desc\n",
    "    atomic_annotations[k] = annotator_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ae32c0",
   "metadata": {},
   "source": [
    "### Match the keysteps to atomic annotations takewise. for each annotator from each take, do the following:\n",
    "1. give the segment a unique id: this is a hash of the take and the segment_id within the take.\n",
    "2. identify the start and end times of the segment.\n",
    "3. from the atomic annotations, find all the instances which falls between this start and end time.\n",
    "4. concatenate these statements end to end - this forms the textual description of the keystep per annotator.\n",
    "5. if there is no atomic action description between the start and end times of a keystep from any of the annotator, then the textual description of that keystep would be the concatenation of the action descriptions from closest before and after action descriptions from any of the randomly sampled annotator. \n",
    "6. note that a single atomic descrption can be matched to multiple keysteps - since the keysteps segments can be overlapping. But this happens rarely, like 75/4262 times or lesser.\n",
    "7. To fuse texts from different annotators, we just concatenate them end to end - but there should be better ways of doing this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6cfa262c",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_to_text = defaultdict(list) ## dict with list values\n",
    "segment_to_meta = dict()\n",
    "segment_to_annotation = dict()\n",
    "take_uid = takes[0] \n",
    "\n",
    "for take_uid in takes:\n",
    "    segment_list = keystep_segments[take_uid] ## list\n",
    "    annotator_dict = atomic_annotations[take_uid] ## dict: ann_id:list of descriptions.\n",
    "\n",
    "    for idx, segment in enumerate(segment_list):\n",
    "        segment_hash = str(get_hash(str(take_uid) + str(idx)))\n",
    "        segment_to_annotation[segment_hash] = segment\n",
    "        start_time = segment['start_time']\n",
    "        end_time = segment['end_time']\n",
    "        \n",
    "        text_dict = dict()\n",
    "        best_exo = []\n",
    "        for aid in annotator_dict:\n",
    "            ann_desc = annotator_dict[aid]\n",
    "            ann_text = []\n",
    "            \n",
    "            for desc in ann_desc:\n",
    "                if start_time <= desc['timestamp'] <= end_time:\n",
    "                    ## this atomic description falls inside the segment - so should correspond to the action.\n",
    "                    ann_text.append(desc['text'][2:]) ## Ignore the subject ID.\n",
    "                    best_exo.append(desc['best_exo'])\n",
    "            if len(ann_text):\n",
    "                ann_text = \" \".join(ann_text)\n",
    "                text_dict[aid] = ann_text\n",
    "        \n",
    "        len_text = sum([len(v) for v in text_dict.values()])\n",
    "        if len_text == 0:\n",
    "            aid = random.sample(list(annotator_dict.keys()),1)[0]\n",
    "            ann_desc = annotator_dict[aid]\n",
    "            ann_text = []\n",
    "            for jdx in range(len(ann_desc)):\n",
    "                if jdx==(len(ann_desc)-1) or (ann_desc[jdx]['timestamp'] < start_time and ann_desc[jdx+1]['timestamp'] > start_time):\n",
    "                    ann_text.append(ann_desc[jdx]['text'][2:])\n",
    "                    best_exo.append(ann_desc[jdx]['best_exo'])\n",
    "                    break\n",
    "            if len(ann_desc) and (ann_desc[0]['timestamp'] > end_time):\n",
    "                    ann_text.append(ann_desc[0]['text'][2:])\n",
    "                    best_exo.append(ann_desc[0]['best_exo'])\n",
    "            else:\n",
    "                for jdx in range(1,len(ann_desc)):\n",
    "                    if (ann_desc[jdx]['timestamp'] > end_time and ann_desc[jdx-1]['timestamp'] < end_time):\n",
    "                        ann_text.append(ann_desc[jdx]['text'][2:])\n",
    "                        best_exo.append(ann_desc[jdx]['best_exo'])\n",
    "                        break\n",
    "            \n",
    "            if len(ann_text):\n",
    "                text_dict[aid] = \" \".join(ann_text)\n",
    "                            \n",
    "        \n",
    "        segment_to_text[segment_hash] = text_dict \n",
    "        segment.update({\n",
    "            'take_uid'  : take_uid,\n",
    "            'segment_id': idx,\n",
    "            'best_exo' : random.sample(best_exo,1)[0],# if len(best_exo) >= 1 else {}\n",
    "#             'domain'   : take_uid_to_name[take_uid]\n",
    "        })\n",
    "        \n",
    "        segment_to_meta[segment_hash] = segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147aa47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"cooking_keystep_text.json\", \"w\") as fh:\n",
    "    json.dump({'text':segment_to_text, 'metadata':segment_to_meta}, fh, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b2149f",
   "metadata": {},
   "source": [
    "## Extract labels at L1 hierarchy for all the segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916968a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "keysteps = json.load(open(\"annotations/keystep_train.json\"))\n",
    "annotations = keysteps['annotations']\n",
    "taxonomy = keysteps['taxonomy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0fda57",
   "metadata": {},
   "outputs": [],
   "source": [
    "cooking = ['Making Coffee latte',\n",
    " 'Making Cucumber & Tomato Salad',\n",
    " 'Cooking Scrambled Eggs',\n",
    " 'Cooking an Omelet',\n",
    " 'Making Milk Tea',\n",
    " 'Making Sesame-Ginger Asian Salad',\n",
    " 'Cooking Tomato & Eggs',\n",
    " 'Making Chai Tea',\n",
    " 'Cooking Noodles',\n",
    " 'Cooking Sushi Rolls',\n",
    " 'Cooking Pasta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563f5c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_wise_mapping = {}\n",
    "for scenario in cooking:\n",
    "    \n",
    "    ## compute the parent tree.\n",
    "    idx_to_parent = {}\n",
    "    child_ids = []\n",
    "    idx_to_name = {}\n",
    "    for c,m in taxonomy[scenario].items():\n",
    "        idx_to_name[m['id']] = m['name']\n",
    "        idx_to_parent[m['id']] = m['parent_id']\n",
    "        if m['is_leafnode']:\n",
    "            child_ids.append(m['id'])\n",
    "    \n",
    "    ## map the child labels to the parents.\n",
    "    mapping = {}\n",
    "    for cid in child_ids:\n",
    "        curr = cid\n",
    "        while idx_to_parent[curr] != 0:\n",
    "            curr = idx_to_parent[curr]\n",
    "        mapping[cid] = idx_to_name[curr]\n",
    "        \n",
    "    scenario_wise_mapping[scenario] = mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4ff9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_to_ann = {}\n",
    "all_labels = []\n",
    "for take_uid in takes:\n",
    "    ann = annotations[take_uid]\n",
    "    if ann[\"scenario\"] in cooking:\n",
    "        for idx, seg in enumerate(ann[\"segments\"]):\n",
    "            segment_hash = str(get_hash(str(take_uid) + str(idx)))\n",
    "            label_remapped_name = scenario_wise_mapping[ann[\"scenario\"]][seg['step_id']]\n",
    "            all_labels.append(label_remapped_name)\n",
    "#             label_remapped_id = label_to_idx[label_remapped_name]\n",
    "            seg.update({\n",
    "#                 'l1_label' : label_remapped_id,\n",
    "                'l1_label_name' : label_remapped_name,\n",
    "                'take_uid'      : take_uid,\n",
    "                'segment_id'    : idx,\n",
    "                'scenario'      : ann['scenario']\n",
    "            })\n",
    "            segment_to_ann[segment_hash] = seg\n",
    "    else:\n",
    "        assert 5==6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc0bd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = list(sorted(set(all_labels)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2ad797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k,ann in segment_to_ann.items():\n",
    "#     ann.update({\n",
    "#         'l1_label' : label_to_idx[ann['l1_label_name']]\n",
    "#     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f056e452",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"cooking_keystep_annotation.json\", \"w\") as fh:\n",
    "    json.dump({'annotation':segment_to_ann}, fh, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f5a8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = [c[\"l1_label_name\"] for c in segment_to_ann.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfc7028",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = Counter(label_list) #dict(sorted(Counter(label_list).items(), key=lambda v:v[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7abc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_labels = [l for l,v in label_dict.items() if v>=5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa7982f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(valid_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b479b426",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_label = {idx:l for idx,l in enumerate(valid_labels)}\n",
    "label_to_idx = {v:k for k,v in idx_to_label.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5d2ace",
   "metadata": {},
   "source": [
    "## Create the text training files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a23ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = json.load(open(\"cooking_keystep_text.json\"))\n",
    "seg_to_text = text['text']\n",
    "seg_to_meta = text['metadata']\n",
    "seg_to_ann = json.load(open(\"cooking_keystep_annotation.json\"))['annotation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d5a9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e990ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [{\"category_name\":cname,  \"category_id\":idx} for idx, cname in idx_to_label.items()]\n",
    "json_data['categories'] = categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a4dd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_seg = defaultdict(list)\n",
    "for seg_id, ann in seg_to_ann.items():\n",
    "    if ann['l1_label_name'] in valid_labels:\n",
    "        label_to_seg[ann['l1_label_name']].append(seg_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62aa31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_ids = []\n",
    "target_ids = []\n",
    "for segments in label_to_seg.values():\n",
    "    source = random.sample(list(segments), int(len(segments)*0.55))\n",
    "    target = [s for s in segments if s not in source]\n",
    "    \n",
    "    source_ids.extend(source)\n",
    "    target_ids.extend(target)\n",
    "seg_ids = {\n",
    "    \"source\" : source_ids,\n",
    "    \"target\" : target_ids\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a651a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fid_to_filename = {k:\"file.jpg\" for k in seg_to_text}\n",
    "fid_to_category = {k:v['l1_label_name'] for k,v in seg_to_ann.items()}\n",
    "fid_to_label = {k:label_to_idx.get(v['l1_label_name'],-1) for k,v in seg_to_ann.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c65ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for domain in ['source', 'target']:\n",
    "    \n",
    "        ## images\n",
    "        all_ids = seg_ids[domain]\n",
    "\n",
    "        clips = []\n",
    "\n",
    "        for fid in all_ids:\n",
    "            clips.append({\n",
    "                \"filename\" : fid_to_filename[fid],\n",
    "                \"id\"       : int(fid),\n",
    "            })\n",
    "\n",
    "        ## annotations\n",
    "\n",
    "        anns = []\n",
    "\n",
    "        for fid in all_ids:\n",
    "\n",
    "            anns.append({\n",
    "                \"segment_id\" : int(fid),\n",
    "                \"category\" : fid_to_label[fid],\n",
    "                'class_name' : fid_to_category[fid]\n",
    "            })\n",
    "\n",
    "        ## metadata\n",
    "\n",
    "        meta = []\n",
    "\n",
    "        for fid in all_ids:\n",
    "            meta_dict = seg_to_meta[fid]\n",
    "            fid = int(fid)\n",
    "            \n",
    "\n",
    "            meta.append({\n",
    "                'segment_id'    : fid,\n",
    "                'start_time'  : meta_dict['start_time'],\n",
    "                'end_time'    : meta_dict['end_time'],\n",
    "                'take_uid'    : meta_dict['take_uid'],\n",
    "                'segment_index' : meta_dict['segment_id'],\n",
    "                'best_exo'    : meta_dict['best_exo']\n",
    "            })\n",
    "            \n",
    "        ## text description\n",
    "        \n",
    "        text_desc = []\n",
    "        \n",
    "        for fid in all_ids:\n",
    "            segment_id = int(fid)\n",
    "            final_text = \"\"\n",
    "            for text in seg_to_text[fid].values():\n",
    "                final_text += text\n",
    "            text_dict = {\n",
    "                'segment_id' : segment_id,\n",
    "                'text_caption' : final_text,\n",
    "                'annotator_texts' : {}\n",
    "            }\n",
    "            for ann_id, text in seg_to_text[fid].items():\n",
    "                text_dict['annotator_texts'][ann_id] = text\n",
    "            \n",
    "            text_desc.append(text_dict)\n",
    "\n",
    "        json_data[\"{}\".format(domain)] = {\n",
    "            \"clips\" : clips,\n",
    "            \"annotations\" : anns,\n",
    "            \"metadata\"    : meta,\n",
    "            \"descriptions\" : text_desc\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51de621e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 22 categories from source and target\n",
    "## ~2000 segment clips from each.\n",
    "with open(\"ego4d_cooking.json\", \"w\") as fh:\n",
    "    json.dump(json_data, fh, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6ef61d",
   "metadata": {},
   "source": [
    "## create text training files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc51b547",
   "metadata": {},
   "outputs": [],
   "source": [
    "ego4d = json.load(open(\"ego4d_cooking.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "738fd06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for domain in ['source', 'target']:\n",
    "    with open(\"/home/tarun/LangBasedGeoDA/data/ego4d/{}_train_split.txt\".format(domain), \"w\") as fh:\n",
    "        write_str = \"\"\n",
    "        for text,ann in zip(ego4d[domain]['descriptions'], ego4d[domain]['annotations']):\n",
    "            for ann_text in text['annotator_texts'].values():\n",
    "                write_str += \"{};{};{};{}\\n\".format(text['segment_id'], ann_text.replace(\"\\n\",\". \").replace(\";\",\" \"), ann['class_name'], ann['category'])\n",
    "        fh.write(write_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8191041a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2301"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ego4d['source']['annotations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a5736b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lens = [len(a['annotator_texts']) for a in ego4d['source']['descriptions']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a95642d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2: 1258, 1: 1043})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26fb093d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3007"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1107*2+793"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c89df4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
