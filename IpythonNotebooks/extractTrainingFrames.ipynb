{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae801a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd0cf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_mapping(n_frames, window_size=32, stride=16, fps=30, frames=True):\n",
    "    \"\"\"\n",
    "    Given a video of length T, window W and stride S, generate mapping between index and the feature window used\n",
    "    to compute the features.\n",
    "    mapping: dict(key:idx, val:(start_frame, end_frame))\n",
    "    So, the feature at position idx is computed using the frames from (start_frame, end_frame).\n",
    "    \"\"\"\n",
    "    ## 0-31 -> 1, 16-47 -> 2, ....\n",
    "    ## also add a loop-back for edge cases\n",
    "    idx = 0\n",
    "    starting_frame, ending_frame = 0, window_size-1\n",
    "    mapping = dict()\n",
    "    while ending_frame < n_frames:\n",
    "        mapping[idx] = (starting_frame, ending_frame)\n",
    "        starting_frame += stride\n",
    "        ending_frame = starting_frame + window_size-1\n",
    "        idx += 1\n",
    "    if n_frames % stride != 0:\n",
    "        ending_frame = n_frames-1\n",
    "        starting_frame = ending_frame - (window_size-1)\n",
    "        mapping[idx] = (starting_frame, ending_frame)\n",
    "    if not frames:\n",
    "        mapping = {k:(v[0]/fps,v[1]/fps) for k,v in mapping.items()}\n",
    "    return mapping\n",
    "\n",
    "def get_matching_indices(start, end, frame_idx, sec=True, fps=30):\n",
    "    \"\"\"\n",
    "    Given a start and end time of a video clip, find what feature_ids correspond to that particular clip.\n",
    "    There can be more than one feature_idx, so we return the list of all such indices.\n",
    "    \"\"\"\n",
    "    if sec:\n",
    "        start = start*fps\n",
    "        end = end*fps\n",
    "    \n",
    "    matching_list = []\n",
    "        \n",
    "    idx = 0\n",
    "    while frame_idx[idx][1] < start:\n",
    "        idx += 1\n",
    "\n",
    "    while (idx < len(frame_idx)) and (frame_idx[idx][0] < end) :\n",
    "        matching_list.append(idx)\n",
    "        idx += 1\n",
    "    \n",
    "    return matching_list\n",
    "\n",
    "def get_frame_indices(start, end, window_size=32, stride=16, sec=True, fps=30):\n",
    "    \"\"\"\n",
    "    Given start and end times of a video clip and a window size and stride, this outputs a list of frame \n",
    "    boundaries which have to be forward passed for computing feature for that clip.\n",
    "    \"\"\"\n",
    "    if sec:\n",
    "        start = int(start*fps)\n",
    "        end = int(end*fps)\n",
    "        \n",
    "    frame_indices = []\n",
    "    \n",
    "    curr_start = start\n",
    "    curr_end = start+(window_size-1)\n",
    "    \n",
    "#     frame_indices.append(curr_start)\n",
    "    \n",
    "    while curr_end <= end:\n",
    "        frame_indices.append((curr_start,curr_end))\n",
    "        curr_start += stride\n",
    "        if curr_end == end:\n",
    "            break\n",
    "        curr_end = curr_start + (window_size-1)\n",
    "        \n",
    "    if curr_end > end:\n",
    "        curr_end = end\n",
    "        curr_start = max(0, curr_end - (window_size-1))\n",
    "        frame_indices.append((curr_start, curr_end))\n",
    "    \n",
    "    return frame_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b123c1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "takes = json.load(open(\"/newdata/tarun/datasets/ego4d/takes.json\"))\n",
    "uid_to_take = {t[\"take_uid\"]:t for t in takes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4be01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_to_frame = {t[\"take_uid\"]:get_index_mapping(int(t['duration_sec'] * 30)) for t in takes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b02b51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_root = \"features/omnivore_video/\"\n",
    "data_file = \"../metadata/ego4d_cooking.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3372aba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ego4d = json.load(open(data_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a140365",
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in ['ego_train', 'ego_val', 'exo_train', 'exo_val', 'ego_train_extra', 'exo_train_extra']:\n",
    "    \n",
    "    segid_to_meta = {m['segment_id']:m for m in ego4d[split][\"metadata\"]}\n",
    "    \n",
    "    features = []\n",
    "    for segid,meta in segid_to_meta.items():\n",
    "\n",
    "        take_uid = meta[\"take_uid\"]\n",
    "\n",
    "        if \"ego\" in split:\n",
    "            all_cameras = uid_to_take[take_uid][\"frame_aligned_videos\"].keys()\n",
    "            ego_camera = [a for a in all_cameras if \"aria\" in a][0]\n",
    "            cam = \"{}_{}\".format(ego_camera, \"rgb\")\n",
    "            stream_info = uid_to_take[take_uid][\"frame_aligned_videos\"][ego_camera]['rgb']\n",
    "            filepath = \"takes/{}/frame_aligned_videos/downscaled/448/{}_{}.mp4\".format(uid_to_take[take_uid][\"root_dir\"], stream_info['cam_id'], stream_info['stream_id'])\n",
    "        else:\n",
    "            if (meta['best_exo'] is None) or (meta['best_exo']['cam_id'] is None):\n",
    "                ## choose a random id\n",
    "                all_cameras = uid_to_take[take_uid][\"frame_aligned_videos\"].keys()\n",
    "                exo_cameras = [a for a in all_cameras if a.startswith((\"gp\",\"cam\"))]\n",
    "                exo_choice = random.sample(exo_cameras,1)[0]\n",
    "                cam = \"{}_0\".format(exo_choice)\n",
    "            else:\n",
    "                ## choose the best id\n",
    "                cam = \"{}_0\".format(meta['best_exo']['cam_id']) \n",
    "                exo_choice = meta['best_exo']['cam_id']\n",
    "            stream_info = uid_to_take[take_uid][\"frame_aligned_videos\"][exo_choice]['0']\n",
    "            filepath = \"takes/{}/frame_aligned_videos/downscaled/448/{}.mp4\".format(uid_to_take[take_uid][\"root_dir\"], stream_info['cam_id'])\n",
    "\n",
    "        features.append({\n",
    "            'id' : segid,\n",
    "            'video_file_name': filepath,\n",
    "            'feature_file_name' : os.path.join(feature_root, \"{}_{}.pt\".format(take_uid,cam)),\n",
    "            'feature_indices' : get_matching_indices(meta[\"start_time\"], meta[\"end_time\"], uid_to_frame[meta[\"take_uid\"]], sec=True),\n",
    "            'frame_indices' : get_frame_indices(meta[\"start_time\"], meta[\"end_time\"], sec=True)\n",
    "        })\n",
    "\n",
    "    ego4d[split]['clips'] = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e5d54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_file, \"w\") as fh:\n",
    "    json.dump(ego4d, fh, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39d1fe6",
   "metadata": {},
   "source": [
    "### verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c14ce069",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cdd1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "takes = json.load(open(\"/newdata/tarun/datasets/ego4d/takes.json\"))\n",
    "id_to_take = {t[\"take_uid\"]:t for t in takes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936c376f",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bda59e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ego4d = json.load(open(\"../metadata/ego4d_cooking.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfb62b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [f[\"feature_file_name\"].split(\"_\")[-2] for f in ego4d[\"ego_train_extra\"][\"clips\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d482449d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in ego4d[\"exo_train\"][\"clips\"]:\n",
    "    if \"gp\" in f[\"feature_file_name\"].split(\"_\")[-2]:\n",
    "        print(f[\"video_file_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f070ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd014c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ego4d[\"exo_train_extra\"][\"clips\"][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea090e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in ['ego_train', 'ego_val', 'exo_train', 'exo_val', 'ego_train_extra', 'exo_train_extra']:\n",
    "    files = ego4d[split]['clips']\n",
    "#     print(len(files))\n",
    "    for f in files:\n",
    "        if not os.path.exists(os.path.join(\"/newdata/tarun/datasets/ego4d/\", f['video_file_name'])):\n",
    "            print(f)\n",
    "            break\n",
    "            \n",
    "        if not os.path.exists(os.path.join(\"/newdata/tarun/datasets/ego4d/\", f['feature_file_name'])):\n",
    "            print(f)\n",
    "            break\n",
    "        \n",
    "        feat = torch.load(os.path.join(\"/newdata/tarun/datasets/ego4d/\", f['feature_file_name']))\n",
    "        assert len(f['feature_indices']) >= 1\n",
    "        assert len(f['frame_indices']) >= 1\n",
    "        index_tensor = torch.tensor(f['feature_indices'], dtype=torch.long)\n",
    "#         print(feat[0:].shape)\n",
    "        segment_feat = feat[index_tensor].mean(0).squeeze()\n",
    "        assert len(segment_feat) >= 1\n",
    "#         print(segment_feat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dba367",
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_to_featfile = {}\n",
    "for split in ['ego_train', 'ego_val', 'exo_train', 'exo_val', 'ego_train_extra', 'exo_train_extra']:\n",
    "    files = ego4d[split]['clips']\n",
    "    uid_to_feat = {f['feature_file_name'].split(\"/\")[-1].split(\"_\")[0]:f['feature_file_name'] for f in files}\n",
    "    uid_to_featfile.update(uid_to_feat)\n",
    "\n",
    "from tqdm import tqdm\n",
    "for t in tqdm(uid_to_featfile):\n",
    "    frame_len = len(uid_to_frame[t])\n",
    "    filename = uid_to_featfile[t]\n",
    "    feat = torch.load(os.path.join(\"/newdata/tarun/datasets/ego4d/\", filename))\n",
    "    assert len(feat) == frame_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0a3f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in ['ego_train', 'ego_val', 'exo_train', 'exo_val', 'ego_train_extra', 'exo_train_extra']:\n",
    "    keys = list(ego4d[split].keys())\n",
    "    key_lens = [len(ego4d[split][k]) for k in keys]\n",
    "    assert len(list(set(key_lens))) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6527ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = ego4d['exo_val']['metadata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a504c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = [(m[\"end_time\"] - m[\"start_time\"])*30 for m in meta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1cb62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9544d38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in meta:\n",
    "    if m[\"end_time\"] == m[\"start_time\"]:\n",
    "        print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ae0ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in ego4d['ego_train_extra']['clips']:\n",
    "    if c[\"id\"] == 1908762465:\n",
    "        print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e056776f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_videos = []\n",
    "for split in ['ego_train', 'ego_val', 'exo_train', 'exo_val', 'ego_train_extra', 'exo_train_extra']:\n",
    "    files = ego4d[split]['clips']\n",
    "    all_videos.extend([f['video_file_name'] for f in files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7680a67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_videos = set(all_videos)\n",
    "with open(\"/newdata/tarun/datasets/ego4d/video_files.txt\", \"w\") as fh:\n",
    "    all_videos = [v for v in all_videos if \"gp04\" in v]\n",
    "    fh.write(\"\\n\".join(all_videos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbf7c697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "951"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(all_videos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda68fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_annotation = {seg[\"segment_id\"]:seg[\"class_name\"] for seg in ego4d[\"ego_train\"][\"annotations\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f06143e",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_text = {seg[\"segment_id\"]:seg[\"text_caption\"] for seg in ego4d[\"ego_train\"][\"descriptions\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8314c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lens = []\n",
    "for split in ['ego_train', 'ego_val', 'exo_train', 'exo_val', 'ego_train_extra', 'exo_train_extra']:\n",
    "    files = ego4d[split]['clips']\n",
    "#     print(len(files))\n",
    "    for f in files:\n",
    "        \n",
    "#         feat = torch.load(os.path.join(\"/newdata/tarun/datasets/ego4d/\", f['feature_file_name']))\n",
    "#         assert len(f['feature_indices']) >= 1\n",
    "#         assert len(f['frame_indices']) >= 1\n",
    "        index_tensor = torch.tensor(f['feature_indices'], dtype=torch.long)\n",
    "        all_lens.append(len(index_tensor))\n",
    "        if len(index_tensor)  <= 4:\n",
    "            print(index_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3242b978",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e067f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(torch.Tensor(all_lens) <= 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2daa152",
   "metadata": {},
   "source": [
    "## Add metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df801296",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52330842",
   "metadata": {},
   "outputs": [],
   "source": [
    "ego4d = json.load(open(\"../metadata/ego4d_cooking.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01161314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['categories', 'ego_train', 'ego_val', 'ego_train_extra', 'exo_train', 'exo_val', 'exo_train_extra'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ego4d.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bbdf4334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['clips', 'annotations', 'metadata', 'descriptions']),\n",
       " dict_keys(['clips', 'annotations', 'metadata', 'descriptions']))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ego4d['ego_train'].keys(), ego4d['ego_train_extra'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f2a2b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subkeys in ['clips', 'annotations', 'metadata', 'descriptions']:\n",
    "    ego4d['ego_train'][subkeys] += ego4d['ego_train_extra'][subkeys]\n",
    "    ego4d['exo_train'][subkeys] += ego4d['exo_train_extra'][subkeys]\n",
    "ego4d.pop(\"ego_train_extra\")\n",
    "ego4d.pop(\"exo_train_extra\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a25ee21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['categories', 'ego_train', 'ego_val', 'exo_train', 'exo_val'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ego4d.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a8cfede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3147\n",
      "3147\n",
      "3147\n",
      "3147\n"
     ]
    }
   ],
   "source": [
    "for subkeys in ['clips', 'annotations', 'metadata', 'descriptions']:\n",
    "    print(len(ego4d['ego_val'][subkeys]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "94665294",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../metadata/EgoExoDA.json\", \"w\") as fh:\n",
    "    json.dump(ego4d, fh, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98301d1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
