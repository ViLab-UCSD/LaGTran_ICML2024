{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe2bf34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "# import os\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff2c38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1').cuda()\n",
    "temp = 0.03"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1cefec",
   "metadata": {},
   "source": [
    "### Caption - label similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33b8a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_accuracy(caption_embeddings, class_embeddings, topk=5):\n",
    "#     similarity_matrix = util.cos_sim(caption_embeddings, class_embeddings)\n",
    "#     pseudoLabel = similarity_matrix.topk(topk, 1).indices    \n",
    "#     gt_label = torch.Tensor([id_to_classid[fid] for fid in all_flickrids]).view(-1,1).repeat(1,topk)\n",
    "#     matched_labels = (torch.Tensor(pseudoLabel) == torch.Tensor(gt_label))\n",
    "#     top1_acc = matched_labels[:,0].sum()/len(gt_label)\n",
    "#     topk_acc = matched_labels.any(1).sum()/len(gt_label)\n",
    "#     return top1_acc, topk_acc\n",
    "\n",
    "# def get_confident(caption_embeddings, class_embeddings, thres=.0025):\n",
    "#     similarity_matrix = util.cos_sim(caption_embeddings, class_embeddings)\n",
    "#     similarity_matrix = torch.nn.functional.softmax(similarity_matrix, dim=-1)\n",
    "#     maxVal, pseudoLabel = similarity_matrix.max(1)\n",
    "#     valid_inds = maxVal > thres\n",
    "    \n",
    "    \n",
    "#     gt_label = torch.Tensor([id_to_classid[fid] for fid in all_flickrids])\n",
    "#     matched_labels = (torch.Tensor(pseudoLabel) == torch.Tensor(gt_label))\n",
    "#     matched_labels = matched_labels[valid_inds]\n",
    "#     top1_acc = matched_labels.sum()/len(valid_inds)\n",
    "# #     topk_acc = matched_labels.any(1).sum()/len(gt_label)\n",
    "#     return top1_acc, sum(valid_inds)/len(similarity_matrix)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2031dcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## category\n",
    "meta = json.load(open(\"../metadata/geoimnet.json\"))\n",
    "\n",
    "cats = {int(c[\"category_id\"]):c[\"category_name\"] for c in meta[\"categories\"]}\n",
    "# cats = [cats[idx].replace(\"_indoor\",\"\").replace(\"_outdoor\",\"\").replace(\"_\",\" \") for idx in range(205)]\n",
    "cats = [cats[idx].replace(\"+\",\" \").replace(\"_\",\" \") for idx in range(600)]\n",
    "# cats = [\"A photo of a {}\".format(c) for c in cats]\n",
    "class_embeddings = model.encode(cats)\n",
    "\n",
    "for dom in [\"usa\", \"asia\"]:# = \"usa\"\n",
    "\n",
    "    id_to_cap = {m[\"image_id\"]:m[\"llm_cap_llama_13b\"] for m in meta[\"{}_train\".format(dom)][\"metadata\"]}\n",
    "\n",
    "    all_flickrids = list(id_to_cap.keys())\n",
    "    all_captions = [id_to_cap[v] for v in all_flickrids]\n",
    "    caption_embeddings = model.encode(all_captions)\n",
    "\n",
    "    similarity_matrix = util.cos_sim(caption_embeddings, class_embeddings)\n",
    "\n",
    "    soft_labels = torch.nn.functional.softmax(torch.Tensor(similarity_matrix)/temp, dim=-1).numpy()\n",
    "\n",
    "    # pseudoLabel = similarity_matrix.argmax(1)\n",
    "\n",
    "    write_str = \"\"\n",
    "    with open(\"../soft_labels/imnet_{}_softPl.txt\".format(dom), \"w\") as fh:\n",
    "        for pl, fid in tqdm(zip(soft_labels, all_flickrids)):\n",
    "            write_str += f\"{fid} \"\n",
    "            vals = list(map(str, pl.tolist()))\n",
    "            write_str += \" \".join(vals)\n",
    "            write_str += \"\\n\"\n",
    "        fh.write(write_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925a9297",
   "metadata": {},
   "source": [
    "## Places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598bf2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## category\n",
    "meta = json.load(open(\"../metadata/geoplaces.json\"))\n",
    "\n",
    "cats = {int(c[\"category_id\"]):c[\"category_name\"] for c in meta[\"categories\"]}\n",
    "cats = [cats[idx].replace(\"_indoor\",\"\").replace(\"_outdoor\",\"\").replace(\"_\",\" \") for idx in range(205)]\n",
    "# cats = [cats[idx].replace(\"+\",\" \").replace(\"_\",\" \") for idx in range(600)]\n",
    "# cats = [\"A photo of a {}\".format(c) for c in cats]\n",
    "class_embeddings = model.encode(cats)\n",
    "\n",
    "for dom in [\"asia\"]:# = \"usa\"\n",
    "\n",
    "    id_to_cap = {m[\"image_id\"]:m[\"llm_cap_llama_13b\"] for m in meta[\"{}_train\".format(dom)][\"metadata\"]}\n",
    "\n",
    "    all_flickrids = list(id_to_cap.keys())\n",
    "    all_captions = [id_to_cap[v] for v in all_flickrids]\n",
    "    caption_embeddings = model.encode(all_captions)\n",
    "\n",
    "    similarity_matrix = util.cos_sim(caption_embeddings, class_embeddings)\n",
    "\n",
    "    soft_labels = torch.nn.functional.softmax(torch.Tensor(similarity_matrix)/temp, dim=-1).numpy()\n",
    "\n",
    "    # pseudoLabel = similarity_matrix.argmax(1)\n",
    "\n",
    "    write_str = \"\"\n",
    "    with open(\"../soft_labels/places_{}_softPl.txt\".format(dom), \"w\") as fh:\n",
    "        for pl, fid in tqdm(zip(soft_labels, all_flickrids)):\n",
    "            write_str += f\"{fid} \"\n",
    "            vals = list(map(str, pl.tolist()))\n",
    "            write_str += \" \".join(vals)\n",
    "            write_str += \"\\n\"\n",
    "        fh.write(write_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0c79f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pseudoLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94251ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfd72a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.load(open(\"../metadata/geoplaces.json\"))['usa_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13bac32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_meta = {m[\"image_id\"]:m for m in data[\"metadata\"]}\n",
    "id_to_category = {m[\"image_id\"]:m for m in data[\"annotations\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2fa83fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image_id': 3802322729, 'datetaken': '2009-07-11 17:55:42', 'caption': 'Midwest fields', 'description': 'Â© This photograph is copyrighted. Under no circumstances can it be reproduced, distributed, modified, copied, posted to websites or printed or published in media or other medium or used for commercial or other uses without the prior written consent and permission of the photographer.', 'tags': 'gold,wheat,fields,farm,farmer,midwest,kansas,nebraska,summer,us,usa,rural,america,pammorris,denverpam,nikon,d40', 'url': 'https://live.staticflickr.com/3532/3802322729_c67c8440e4.jpg', 'llm_cap_llama_13b': 'golden wheat fields in the Midwest.', 'blip1_cap': 'a field full of hay bales with trees in the background', 'blip2_cap': 'many round bales in the field with trees in the background'}\n",
      "{'image_id': 3802322729, 'category': 201, 'class_name': 'wheat_field'}\n"
     ]
    }
   ],
   "source": [
    "random_idx = random.sample(list(id_to_meta.keys()), 1)[0]\n",
    "print(id_to_meta[random_idx])\n",
    "print(id_to_category[random_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63b1ff19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[125666]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30cf1df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
