{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torchvision import transforms, models\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from models import get_model\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from metrics import averageMeter\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(3)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    # ResizeImage(resize_size),\n",
    "    transforms.CenterCrop((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                   std=[0.229, 0.224, 0.225])\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_array(n_samples, n_bins):\n",
    "    \n",
    "    n_samples = np.array(n_samples)\n",
    "    n_samples = n_samples.reshape(n_bins, len(n_samples)//n_bins).mean(1)\n",
    "    return n_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the source and target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe = {\"arch\":\"resnet50\" , \"pretrained\":True}\n",
    "cls = {\"arch\":\"mlpcls\", \"nonlinear\":\"none\", \"feat_size\":[2048,256], \"n_class\":345}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_fe = get_model(fe, verbose=False).cuda()\n",
    "model_cls = get_model(cls, verbose=False).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percls_accuracy(all_pred, all_label, num_class=0):\n",
    "    \"\"\"Computes per class accuracy\"\"\"\n",
    "    num_class = len(set(all_label)) if num_class == 0 else num_class\n",
    "    all_pred = np.asarray(all_pred)\n",
    "    all_label = np.asarray(all_label)\n",
    "\n",
    "    cls_acc = -np.ones([num_class])\n",
    "    for i in range(num_class):\n",
    "        idx = (all_label == i)\n",
    "        if idx.sum() > 0:\n",
    "            cls_acc[i] = (all_pred[idx] == all_label[idx]).mean() * 100.0\n",
    "\n",
    "    return cls_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "source, target = \"sketch\", \"painting\"\n",
    "\n",
    "CBS = True\n",
    "if CBS:\n",
    "    model = fine_net(345, batch_norm=True)\n",
    "    pretrained = torch.load(\"snapshot/domainNet_full_ablation/MemSAC_%s%s_QS_48000_BS_32_tau_0-07_lambda_0_CAS/best_model.pth.tar\"%(source, target))\n",
    "else:\n",
    "    model = fine_net(345)\n",
    "    pretrained = torch.load(\"snapshot/domainNet_full/CDAN/CDAN_%s%s_QS_48000_BS_32_tau_0-007_lambda_0/best_model.pth.tar\"%(source, target))\n",
    "    pretrained = {k.partition(\"module.\")[-1]:v for k,v in pretrained.items()}\n",
    "    \n",
    "# \n",
    "model.load_state_dict(pretrained, strict=True)\n",
    "# \n",
    "model = model.cuda()\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_list = ImageList(\"/newfoundland/tarun/datasets/Adaptation/visDA/\", open(\"./data/visDA_full/%s_test.txt\"%(target)).readlines(), transform=prep.image_test(resize_size=256, crop_size=224))\n",
    "dataset_loader_target = torch.utils.data.DataLoader(dataset_list, batch_size=64, shuffle=False, num_workers=16, drop_last=False)\n",
    "nclasses=345\n",
    "\n",
    "dataset_list = ImageList(\"/newfoundland/tarun/datasets/Adaptation/visDA/\", open(\"./data/visDA_full/%s_test.txt\"%(source)).readlines(), transform=prep.image_test(resize_size=256, crop_size=224))\n",
    "dataset_loader_source = torch.utils.data.DataLoader(dataset_list, batch_size=64, shuffle=False, num_workers=16, drop_last=False)\n",
    "nclasses=345\n",
    "\n",
    "# dataset_list = ImageList(\"/newfoundland/tarun/datasets/Adaptation/OfficeHome/Dataset10072016/\", open(\"./data/officeHome/Product.txt\").readlines(), transform=prep.image_test(resize_size=256, crop_size=224))\n",
    "# dataset_loader_source = torch.utils.data.DataLoader(dataset_list, batch_size=64, shuffle=False, num_workers=16, drop_last=False)\n",
    "# nclasses=65\n",
    "\n",
    "# dataset_list = ImageList(\"/newfoundland/tarun/datasets/birds/\", open(\"./data/cub200/cub200_2011.txt\").readlines(), transform=prep.image_test(resize_size=256, crop_size=224))\n",
    "# dataset_loader_source = torch.utils.data.DataLoader(dataset_list, batch_size=64, shuffle=False, num_workers=16, drop_last=False)\n",
    "# nclasses=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = AverageMeter()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "for idx , (image, labels) in enumerate(dataset_loader_target):\n",
    "    print(\"{}/{}\".format(idx+1, len(dataset_loader_target)), end=\"\\r\")\n",
    "    image = image.cuda()\n",
    "    labels = labels.cuda()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "        predictions = outputs.detach().argmax(1)\n",
    "    correct = torch.sum((predictions == labels).float())\n",
    "    accuracy.update(correct/len(outputs), len(outputs))\n",
    "    all_preds.extend(predictions.cpu().numpy().tolist())\n",
    "    all_labels.extend(labels.cpu().numpy().tolist())\n",
    "print_str = \"\\nCorrect Predictions: {}/{}\".format(int(accuracy.sum), accuracy.count)\n",
    "print_str1 = '\\ntest_acc:{:.4f}'.format(accuracy.avg)\n",
    "print(print_str + print_str1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classwise_accuracy = percls_accuracy(all_preds, all_labels, 345)\n",
    "classwise_accuracy = {i:ca for i,ca in enumerate(classwise_accuracy)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels_source = []\n",
    "for idx, (image, labels) in enumerate(dataset_loader_source):\n",
    "    print(\"{}/{}\".format(idx+1, len(dataset_loader_source)), end=\"\\r\")\n",
    "    all_labels_source.extend(labels.numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_per_class_target = dict(zip(*np.unique(all_labels, return_counts=True)))\n",
    "n_samples_per_class_source = dict(zip(*np.unique(all_labels_source, return_counts=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot wrt source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_sample = sorted(n_samples_per_class_source.items(), key=lambda l : l[1], reverse=True)\n",
    "keyset = [k[0] for k in sorted_sample]\n",
    "n_samples = [k[1] for k in sorted_sample]\n",
    "accuracy = [classwise_accuracy[k] for k in keyset]\n",
    "n_samples = wrap_array(n_samples, n_bins=69)\n",
    "accuracy = wrap_array(accuracy, n_bins=69)\n",
    "\n",
    "reg = LinearRegression().fit(np.array(n_samples).reshape(-1,1), accuracy)\n",
    "print(reg.score(np.array(n_samples).reshape(-1,1), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(np.arange(len(n_samples))*5, n_samples)\n",
    "\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "plt.xlabel(\"Class Id\", fontsize=20)\n",
    "plt.ylabel(\"#samples in class\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "plt.scatter(n_samples, accuracy)\n",
    "ax = plt.gca()\n",
    "ax.invert_xaxis()\n",
    "\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "plt.xlabel(\"#samples in class\", fontsize=20)\n",
    "plt.ylabel(\"Class Accuracy\", fontsize=20)\n",
    "\n",
    "plt.ylim(0,60)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot wrt target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_sample = sorted(n_samples_per_class_target.items(), key=lambda l : l[1], reverse=True)\n",
    "keyset = [k[0] for k in sorted_sample]\n",
    "n_samples = [k[1] for k in sorted_sample]\n",
    "accuracy = [classwise_accuracy[k] for k in keyset]\n",
    "n_samples = wrap_array(n_samples, n_bins=43)\n",
    "accuracy = wrap_array(accuracy, n_bins=43)\n",
    "\n",
    "reg = LinearRegression().fit(np.array(n_samples).reshape(-1,1), accuracy)\n",
    "print(reg.score(np.array(n_samples).reshape(-1,1), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(np.arange(len(n_samples))*5, n_samples)\n",
    "\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "plt.xlabel(\"Class Id\", fontsize=20)\n",
    "plt.ylabel(\"#samples in class\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "plt.scatter(n_samples, accuracy)\n",
    "ax = plt.gca()\n",
    "ax.invert_xaxis()\n",
    "\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "plt.xlabel(\"#samples in class\", fontsize=20)\n",
    "plt.ylabel(\"Class Accuracy\", fontsize=20)\n",
    "\n",
    "plt.ylim(0,54)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
