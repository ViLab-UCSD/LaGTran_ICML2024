seed: 1
model:
    feature_extractor:
        arch: timesformerb_8f
        pretrained: true
    classifier:
        arch: mlpcls
        nonlinear: relu
        # norm: 1 # LDAM
        feat_size: [768, 256] # [feat_dim, bottleneck_dim]
        n_class: 31 # domainnet
    ### comment random_layer if not using it; use random layer when d > 4096
    # random_layer:
    #     arch: randomlyr
    #     input_dim_list: [256, 31] # [bottleneck_dim, n_class]
    #     output_dim: 1024 # random_dim
    ###
    discriminator:
        arch: advnet
        # in_feature: 1024 # random_dim (if using random layer)
        in_feature: 256 # bottleneck_dim x n_class (if not using random layer)
        hidden_size: 1024
data:
    source:
        loader: VideoLoader
        data_root: /data/
        n_workers: 4
        drop_last: true
    target:
        loader: VideoLoader
        data_root: /data/
        n_workers: 4
        drop_last: true
training:
    trainer: cdan
    losses:
        loss_cls:
            name: cross_entropy
        loss_d:
            name: cdan
            use_entropy: false # true for CDAN+E; false for CDAN
            coeff: 1
    iteration: 100004
    batch_size: 32
    # batch_size: 256
    val_interval: 5000
    save_interval: 10000
    print_interval: 2500
    optimizer:
        name: sgd
        # lr: 0.03
        momentum: 0.9
        weight_decay: 0.0005
        nesterov: true
    scheduler:
        init_lr: 0.003
        name: inv
        gamma: 0.001
        power: 0.75
    # scheduler:
    #     name: multiStepLr
    #     gamma: 0.1
    #     milestones: [35000,50000,60000]
    resume:
        model: 
        load_cls: false
        param_only: true
exp: exp
